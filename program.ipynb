{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3a0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re#helps for searching words in texts or paragraph\n",
    "import nltk#natural language tool kit\n",
    "from nltk.corpus import stopwords#contains non important words\n",
    "from nltk.stem import PorterStemmer#removes prefix or suffix and gives us root word\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer#coverts str into number for understanding of machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307c9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Roshan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords if not already\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd400878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "fake_news_data = pd.read_csv(r\"C:\\Users\\Roshan\\Downloads\\Fake.csv.zip\")\n",
    "true_news_data = pd.read_csv(r\"C:\\Users\\Roshan\\Downloads\\True.csv.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1048e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf80cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming function\n",
    "def stemming(content):\n",
    "    # Remove special characters and numbers\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', str(content))\n",
    "    # Convert to lowercase\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Tokenize into words\n",
    "    words = stemmed_content.split()\n",
    "    # Stem each word\n",
    "    stemmed_words = [port_stem.stem(word) for word in words]\n",
    "    # Join back into a single string\n",
    "    return \" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8425aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add labels\n",
    "fake_news_data[\"label\"] = 0   # 0 → Fake\n",
    "true_news_data[\"label\"] = 1   # 1 → True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45722e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Combine datasets\n",
    "news_data = pd.concat([fake_news_data, true_news_data], axis=0)\n",
    "news_data = news_data.sample(frac=1) # shuffle rows becz If you split this\n",
    "#directly into train/test, the train set might get mostly fake and the test set\n",
    "#  mostly true (or vice versa).\n",
    "\n",
    "#That makes the model biased and accuracy meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1557770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply stemming\n",
    "news_data['text'] = news_data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfba8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Features & labels\n",
    "X = news_data['text'].values\n",
    "y = news_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e07f97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTfidfVectorizer\\n\\nConverts text into numerical feature vectors so ML models can understand it.\\n\\nTF-IDF = Term Frequency – Inverse Document Frequency\\n\\nTF: How often a word appears in a document.\\n\\nIDF: How unique the word is across all documents (rare words get more weight).\\n\\nCommon words like “the”, “is”, “and” → low weight.\\n\\nImportant words like “election”, “vaccine”, “policy” → high weight.\\n\\n2. Parameters\\n\\nstop_words='english' → removes common English stopwords (“a”, “an”, “the”, “and”…).\\n\\nmax_df=0.7 → ignores words that appear in 70%+ of documents, since they don’t help distinguish fake vs true.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "'''\n",
    "TfidfVectorizer\n",
    "\n",
    "Converts text into numerical feature vectors so ML models can understand it.\n",
    "\n",
    "TF-IDF = Term Frequency – Inverse Document Frequency\n",
    "\n",
    "TF: How often a word appears in a document.\n",
    "\n",
    "IDF: How unique the word is across all documents (rare words get more weight).\n",
    "\n",
    "Common words like “the”, “is”, “and” → low weight.\n",
    "\n",
    "Important words like “election”, “vaccine”, “policy” → high weight.\n",
    "\n",
    "2. Parameters\n",
    "\n",
    "stop_words='english' → removes common English stopwords (“a”, “an”, “the”, “and”…).\n",
    "\n",
    "max_df=0.7 → ignores words that appear in 70%+ of documents, since they don’t help distinguish fake vs true.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a95fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9893646639567905\n",
      "Testing Accuracy: 0.9810690423162584\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=2\n",
    ")\n",
    "\n",
    "# Step 7: Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Accuracy\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b42daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(text):\n",
    "    # clean & stem the text\n",
    "    text = stemming(text)\n",
    "    # convert text into numbers\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    # make prediction\n",
    "    pred = model.predict(text_vector)\n",
    "    # return result\n",
    "    if pred == 1:\n",
    "        return \"✅ True News\"\n",
    "    else:\n",
    "        return \"❌ Fake News\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25e0171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ✅ True News\n"
     ]
    }
   ],
   "source": [
    "# Example test\n",
    "print(\"Prediction:\", predict_news(\"The following statementsÂ were posted to the verified Twitter accounts of U.S. President Donald Trump, @realDonaldTrump and @POTUS.  The opinions expressed are his own.Â Reuters has not edited the statements or confirmed their accuracy.  @realDonaldTrump : -\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffade5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mine_vs_rock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
